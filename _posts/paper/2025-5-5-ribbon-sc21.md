---
title: SC21 - RIBBON 논문 분석
author: blakewoo
date: 2025-5-5 22:00:00 +0900
categories: [Paper]
tags: [Paper, SC21] 
render_with_liquid: false
---


# Ribbon Paper
## 1. 개요
슈퍼컴퓨터 21년도에 올라온 논문이다. 논문 풀네임은 "Ribbon: Cost-Effective and QoS-Aware Deep Learning Model Inference using a
Diverse Pool of Cloud Computing Instances"이다. 
직역하자면 "다양한 클라우드 컴퓨팅 인스턴스 풀을 활용한 비용 효율적이고 QoS를 생각하는 딥 러닝 모델 추론"이 되겠다.   
딥러닝 모델을 제공하기 위해 적절한 인스턴스를 어떻게 지정할 것인가에 대한 논문 되겠다.

## 2. 딥러닝 모델 종류
이 논문에서는 대상 딥러닝 모델 종류를 아래와 같이 정의했다.

![img.png](../../assets/blog/paper/RIBBON/img.png)

- CANDLE   
  대규모의 완전 연결 딥러닝 모델로, 암 세포 예측에 사용된다.


- ResNet
  마이크로 소프트에서 만든 합성곱 신경망으로 컴퓨터 비전에서 이미지 분류 및 개체 찾기 등에서 널리 사용된다.


- VGG
  합성곱 신경망으로 DLHUB에서 사용 가능하다. 이미지 인식 분야에서 많이 사용된다.


- MT-WND
  Multi-Task Wide and Deep, 추천 모델. 여러 DNN 예측자를 병렬로 사용하여 클릭 처리율(CTR), 평점과 같은 여러 지표를 예측한다. YouTube 비디오 추천에 사용된다.


- DIEN
  알리바바에 의해서 만들어진 Deep Interest Evoluation Network이다. RNN의 변형인 GRU로 만들어졌으며 시계열 정보를 캡쳐하는데 사용한다. E 커머스에서 사용한다.

## 3. 대상 인스턴스
여기서는 AWS의 인스턴스들을 사용했다고 했다.   
이는 다양한 Computing 인스턴스를 제공하기 때문이다.

![img_1.png](../../assets/blog/paper/RIBBON/img_1.png)

대략적인 설명은 아래와 같다.

t3, m5, m5n 은 cpu 성능과 메모리, 네트워크 대역폭등이 밸런스 있게 나눠진 인스턴스 타입으로
뒤에 n이 붙은건 인텔 Vector Neural Network Instructions를 지원하는 타입이다.

c5, c5a는 컴퓨트 성능 더 필요한 워크로드에 적합한 인스턴스 타입으로 a가 붙으면 amd cpu를 사용한다는 뜻이다.

r5, r5n은 메모리가 필요한 타입으로 다른 인스턴스에 비해 size가 올라갈 수록 메모리 할당량이 크게 늘어난다.
메모리 집약적 어플리케이션에 유용하기에 DB 같이 메모리를 많이 사용하는 워크로드에 적합하다.

g4dn은 GPU가 달린 인스턴스로 그래픽이나 머신러닝에 필요한 워크로드에 적합하다.

뭐 가격 차이가 얼마나 나길래 이렇게 다양하게 쓰는가 하겠지만 아래의 표를 보면 생각이 달라질 것이다.

![img_2.png](../../assets/blog/paper/RIBBON/img_2.png)

## 4. 각 모델의 인스턴스별 효율성
논문에서 갖고 온 아래의 그림을 보자.

![img_3.png](../../assets/blog/paper/RIBBON/img_3.png)

유튜브에서 우리를 유혹하는 알고리즘인 MT-WND를 기준으로 성능과 비용 효율성을 나타낸 그래프이다.
그래픽 카드가 들어간 g4dn계통 인스턴스는 성능이 좋지만, 비용이 높고, 다른건 대부분 성능은 낮지만, 비용이 낮다.
단, 그중에서 메모리 집약적 타입인 r계통에서는 가성비가 준수하게 나오는데, 이렇게 AI 모델별로 메모리 집약적이냐 컴퓨팅 집약적이냐
혹은 GPU 집약적이냐에 따라 각기 다른 최적의 해가 있는것이다.
문제는 이뿐만이 아니다.

## 5. QoS 만족
서비스라면 사용자의 요청에 대해서 특정 시간내에 응답을 해야하는 의무를 지닌다.   
Quality of Service란 해당 서비스의 품질을 말하는 것인데, 여기서 QoS를 응답시간으로 지정했다.   
아래의 그래프를 보자.

![img_4.png](../../assets/blog/paper/RIBBON/img_4.png)

그림은 X+Y의 조합시 MT-WND 모델의 QoS를 만족하는 것에 대한 그래프이다.
여기서 앞의 숫자 X는 g4n 인스턴스의 개수, Y는 t3 인스턴스의 개수이다.
g4dn는 t3에 비해 3배 정도 비싼데, 이를 조합해서 QoS를 만족하며 비용에 대한 최적이 가능한지를 가늠할 수 있다.

위 그래프를 보면 두 가지를 알 수 있다.
- 비용이 비슷한 구성도 QoS 만족도가 상당히 다를 수 있음
- 비용이 상당히 다른 구성도 QoS 만족도가 비슷할 수 있음

위 사실에 근거하여 논문에서는 최적의 조합을 찾는 법에 대해서 말한다.

## 6. 최적해 찾기
기본적으로 이 문제는 아래의 문제를 내포하고 있다.

1. 검색 공간이 너무 크다
2. 풀 구성과 QoS 만족도 간의 상호작용을 수학적으로 나타내기 어렵다
2. 특정 배치 크기와 쿼리에 해당하는 사전 지식이 없음을 가정해야 한다

그래서 이 논문 저자들이 제안하는 방법은 바로 베이지안 최적화이다.

> ※ 추가 업데이트 및 퇴고 예정
{: .prompt-tip }


# 참고문헌
- Li, Baolin, Rohan Basu, Roy, Tirthak, Patel, Vĳay, Gadepally, Karen, Gettings, and Devesh, Tiwari. "RIBBON: cost-effective and qos-aware deep learning model inference using a diverse pool of cloud computing instances." . In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. Association for Computing Machinery, 2021.
- [베이지안 최적화](https://data-scientist-brian-kim.tistory.com/88 )

