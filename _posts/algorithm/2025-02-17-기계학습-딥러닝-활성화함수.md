---
title: 기계학습 - Deep learning - 활성화함수
author: blakewoo
date: 2025-2-17 15:30:00 +0900
categories: [Algorithm and AI]
tags: [Deep learning, AI, Machine Learning] 
render_with_liquid: false
use_math: true
---

# Deep learning
## 1. 활성화 함수(Activation Function)
### 1) 개요
은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수를 활성화 함수(Activation Function)이라고 한다.   
기본적으로 이 활성화 함수는 비선형 함수여야한다.   
비선형 함수라는 말은 그래프를 그릴때 직선하나로 그릴 수 없는 함수를 말한다.

### 2) 종류
#### a. 계단 함수(Step function)
거의 사용되지는 않는 함수다.

![img.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img.png)

#### b. 시그모이드 함수(Sigmoid function)

![img_1.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img_1.png)

그래프로 그릴시 위와 같이 나타낼 수 있는데, 식으로 나타낼 경우 아래와 같이 나타낼 수 있다.

$$H(x)=\frac{1}{1+e^{-(wx+b)}} = sigmoid(wx+b) = \sigma (wx+b)$$

그래프를 보면 출력값이 0 또는 1에 가까워지면 기울기가 완만해지는 모습을 볼 수 있는데 이로 인해 미분시 0에 가까운 값이 나온다.
중반부분 -2에서 2사이의 부분에서 미분시에 최대값은 0.25가 나오는데 어떤 값이든 0.25 이하로 나온다는 뜻이기 때문에
이후 서술할 역전파 과정에서 기울기 소실이라는 문제가 나타난다.
이는 차후에 다시 언급할 것이지만 이 때문에 은닉층에는 시그모이드 함수가 잘 쓰이지 않고 출력층에서나 사용된다.

#### c. 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function)

![img_2.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img_2.png)

입력값을 -1과 1사이의 값으로 변환하는 함수이다.
이 역시 출력이 -1이나 1에 가까워지면 미분시 기울기가 0에 가까워지지만 중반부의 최대 값이 1이기 때문에 시그모이드보다는 은닉층에서
선호되는 함수이다.

#### d. 렐루 함수(ReLU)

![img_3.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img_3.png)

은닉층에서 가장 인기 있는 함수로 수식은 $f(x)=max(0,x)$ 이다.   
입력값이 음수일 경우 무조건 기울기가 0, 미분값이 0이기 때문에 어떤 값을 곱해도 0이 되어버린다.
이런 경우 죽은 뉴런이라고 부른다.

#### e. 리키 렐루(Leaky ReLU)

![img_4.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img_4.png)

위의 죽은 뉴런을 줄이기 위한 여러 종류의 변종이 나타났는데 리키 렐루 또한 그 종류 중 한개이다.   
입력값이 음수일때 0이 아닌 매우 작은 값을 반환하는 것으로 수식은 $f(x) = max(ax,x)$ 로 a는 일반적으로 0.01의 값을 가진다.

#### f. 소프트맥스 함수

![img_5.png](/assets/blog/algorithm/AI/deeplearning/활성화함수/img_5.png)

출력 층에서 주로 사용되는 함수로 다중 클래스 분류문제에 주로 사용되는 함수이다.

> ※ 본 포스팅은 추가적으로 업데이트 될 예정이다. 내가 제대로 정리한게 맞는지 검증이 필요하다.
{: .prompt-tip }


# 참고 자료
- 인공지능 개념 및 응용 3판 Artificial Intelligence Concepts and Applications (2013년) - 도용태, 김일곤, 김종완, 박창현, 강병호 저,
  사이텍미디어
- [위키독스 - 딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)  
- Machine Learning, Tom Mitchell, McGraw Hill, 1997.
- [geeksforgeeks - Type of machine learning](https://www.geeksforgeeks.org/types-of-machine-learning/)
