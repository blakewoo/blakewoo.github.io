---
title: GPU 프로그래밍 - 텐서코어
author: blakewoo
date: 2025-5-23 16:00:00 +0900
categories: [GPU Programming]
tags: [GPU, Tensor core] 
render_with_liquid: false
---

# 텐서 코어(Tensor Core)
## 1. 개요
행렬연산에 특화되어있는 Nvidia에서 만든 코어이다. 기본적으로 이 텐서 코어는 D = A * B + C
와 같은 형태의 연산에 특화되어있는 코어이다.    
딥러닝 연산의 대부분이 가중치와 편향 계산인 만큼 텐서코어의 이와 같은 특성은 AI에 특화되어있다고 볼 수 있다.

## 2. 구조
### 1) 지원하는 자료형
텐서코어에서는 IEEE 754에서 정의한 공식적인 자료형 외에 Nvidia에서 자체적으로 만든 자료형도 지원을 한다.  
아래는 Ampere 버전의 NVIDIA GPU에서 텐서코어에서 지원하는 자료형에 종류에 대해 간략하게 설명해둔 표이다.

<table>
    <tr>
        <td>Format</td>
        <td>Total bits</td>
        <td>Sign Bits</td>
        <td>Exponents Bits</td>
        <td>Mantissa Bits</td>
    </tr>
    <tr>
        <td>BF16(Brain Float 16)</td>
        <td>16</td>
        <td>1</td>
        <td>8</td>
        <td>7</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>16</td>
        <td>1</td>
        <td>5</td>
        <td>10</td>
    </tr>
    <tr>
        <td>TF32(Tensor Float 32)</td>
        <td>19(Effectively 32)</td>
        <td>1</td>
        <td>8</td>
        <td>10</td>
    </tr>
    <tr>
        <td>FP32</td>
        <td>32</td>
        <td>1</td>
        <td>8</td>
        <td>23</td>
    </tr>
</table>

### 2) 지원하는 연산 형태
#### a. 연산 기본구조
기본적으로 총 4개의 2차원 행렬이 등장한다.   

$$ D = A \times B + C $$

라고 한다면 각각 Matrix A, Matrix B, Accumulator C, Accumulator D라고 하자.
연산은 아래와 같은 형태로 이루어진다.

![img.png](/assets/blog/gpu/tensor_core/img.png)

위 경우는 A,B는 FP16이고 C,D가 FP32가 되는 경우인데,
A와 B 연산과정에서 확장되어 FP32가 되는 것이다.
이렇게 연산 과정에서 Precision이 변경되는 연산 종류를 많이 지원한다.

#### b. 연산 종류
아래의 Matrix size는 정사각 행렬을 기준으로 하는 것을 16으로 되어있다면 16x16으로 이해하면 된다. 

* Standard
<table>
    <tr>
        <td>Matrix A</td>
        <td>Matrix B</td>
        <td>Accumulator</td>
        <td>Matrix Size(m-n-k)</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>float</td>
        <td>16x16x16</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>float</td>
        <td>32x8x16</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>float</td>
        <td>8x32x16</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>FP16</td>
        <td>16x16x16</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>FP16</td>
        <td>32x8x16</td>
    </tr>
    <tr>
        <td>FP16</td>
        <td>FP16</td>
        <td>FP16</td>
        <td>8x32x16</td>
    </tr>
    <tr>
        <td>unsigned char</td>
        <td>unsigned char</td>
        <td>int</td>
        <td>16x16x16</td>
    </tr>
    <tr>
        <td>unsigned char</td>
        <td>unsigned char</td>
        <td>int</td>
        <td>32x8x16</td>
    </tr>
    <tr>
        <td>unsigned char</td>
        <td>unsigned char</td>
        <td>int</td>
        <td>8x32x16</td>
    </tr>
    <tr>
        <td>signed char</td>
        <td>signed char</td>
        <td>int</td>
        <td>16x16x16</td>
    </tr>
    <tr>
        <td>signed char</td>
        <td>signed char</td>
        <td>int</td>
        <td>32x8x16</td>
    </tr>
    <tr>
        <td>signed char</td>
        <td>signed char</td>
        <td>int</td>
        <td>8x32x16</td>
    </tr>
</table>

* Alternate Floating-Point Support

<table>
    <tr>
        <td>Matrix A</td>
        <td>Matrix B</td>
        <td>Accumulator</td>
        <td>Matrix Size(m-n-k)</td>
    </tr>
    <tr>
        <td>bf16</td>
        <td>bf16</td>
        <td>float</td>
        <td>16x16x16</td>
    </tr>
    <tr>
        <td>bf16</td>
        <td>bf16</td>
        <td>float</td>
        <td>32x8x16</td>
    </tr>
    <tr>
        <td>bf16</td>
        <td>bf16</td>
        <td>float</td>
        <td>8x32x16</td>
    </tr>
    <tr>
        <td>tf32</td>
        <td>tf32</td>
        <td>float</td>
        <td>16x16x8</td>
    </tr>
</table>

* Double-Precision Support

<table>
    <tr>
        <td>Matrix A</td>
        <td>Matrix B</td>
        <td>Accumulator</td>
        <td>Matrix Size(m-n-k)</td>
    </tr>
    <tr>
        <td>double</td>
        <td>double</td>
        <td>double</td>
        <td>8x8x4</td>
    </tr>
</table>

* Experimental Support For Sub-byte Operations

<table>
    <tr>
        <td>Matrix A</td>
        <td>Matrix B</td>
        <td>Accumulator</td>
        <td>Matrix Size(m-n-k)</td>
    </tr>
    <tr>
        <td>unsigned 4bytes</td>
        <td>unsigned 4bytes</td>
        <td>int</td>
        <td>8x8x32</td>
    </tr>
    <tr>
        <td>signed 4bytes</td>
        <td>signed 4bytes</td>
        <td>int</td>
        <td>8x8x32</td>
    </tr>
    <tr>
        <td>binary 1byte</td>
        <td>binary 1byte</td>
        <td>int</td>
        <td>8x8x128</td>
    </tr>
</table>



> ※ 내용 업데이트 및 추가적인 검증 예정
{: .prompt-tip }

# 참고문헌
- 서강대학교 임인성 교수님 - 기초 GPU 프로그래밍 수업 자료
- [NVIDIA - NVIDIA ADA GPU ARCHITECTURE](https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf)
