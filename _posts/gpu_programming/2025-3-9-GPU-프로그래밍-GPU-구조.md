---
title: GPU 프로그래밍 - CUDA 용어 및 구조
author: blakewoo
date: 2025-3-12 10:00:00 +0900
categories: [GPU Programming]
tags: [GPU, CUDA] 
render_with_liquid: false
---

# CUDA
## 1. 종류
일반적인 용도의 병렬 컴퓨팅을 위한 프로그램을 할 수 있는 모델이라고 생각하면 된다.

소위 말하는 CUDA에는 사실 두 가지 종류가 있다.
### Driver library
- NVIDIA 드라이버를 설치하면 자동으로 설치된다.
- 저수준의 CUDA 프로그래밍을 목적으로 한다
- 지원하는 API이름은 CUDA Driver API이다.
- 라이브러리 명    
  (static) cuda.lib이나 libcuda.a    
  (dynamic) cuda.dll이나 libcuda.so
- 헤더파일은 cuda.h  

### Runtime library
- NVIDIA CUDA Toolkit 설치시 설치된다.
- 고수준의 CUDA 프로그래밍을 목적으로 한다.
- 지원하는 API이름은 CUDA Runtime API이다.
- 라이브리 명    
  (static) cudart.lib 이나 libcudart.a    
  (dynamic) cudart.dll 이나 libcudart.so
- 헤더파일은 cuda_runtime.h

## 2. 용어들
### 1) Kernel
GPU에서 구동될 수 있는 프로그램을 말한다.

### 2) Thread
한 개의 코어가 하는 각각의 작업 하나하나를 말한다.

#### a. thread ID
전체의 Thread 리스트 중에서의 구분자를 말한다. 일반적으로 배열 번호이다.

#### b. thread Index
Thread block(아래에 서술)안의 몇 번째 Thread인지 구분할 수 있는 번호이다.

### 3) Thread block
Thread의 묶음을 말한다. 몇 개의 Thread를 1 Thread block으로 쓸지는 그때그때 다르다.   
최대 1024개의 Thread까지 지정할 수 있다.

#### 1) Thread block dimesion
Thread block이 몇 개의 Thread로 이루어져있는지를 말한다.

### 4) Grid
Thread block들의 묶음이다.

#### 1) Grid Dimension
Grid가 몇 개의 Thread block으로 이루어져있는지 말한다.

### 5) Warp
Thread block에서 동일한 크기로 나뉜 조각을 말하며 CUDA에서는 32 Threads로 지정되어있다.   
GPU에서는 이 Warp를 기준으로 처리한다.

## 3. 구조
아래는 Geforce 3000번대인 ADA AD102 GPU의 구조이다.   
칩셋 종류마다 어느정도 차이는 있지만 각각의 컴포넌트의 역할이 바뀌진 않는다.

### 1) GPC

![img.png](/assets/blog/gpu/basic_structure/img.png)

그래픽 카드의 chip을 보면 GPCs(Graphics Processing Clusters)라는 것으로 이루어져있다.
여기서는 12개의 GPC로 이루어져있으며 그 외에 Optical Flow Accelerator나 NVENC 같은 부속 부품으로 이루어져있고
6개의 GPC 쌍의 중간에는 L2 Cache가 자리하고 있다.

이 GPC의 내부는 아래와 같다.

![img_1.png](/assets/blog/gpu/basic_structure/img_1.png)

GPC 마다 1개의 Raster Engine이 있고 6개의 TPC(Texture Processing Cluster)가 있으며
2개의 Raster Operations(ROPs, 가장 GPC 가장 아래에 8개씩 두 개의 파란색) 이 있다.
그리고 TPC는 2개의 SM과 1개의 PolyMorph Engine으로 이루어져있다.


### 2) SM
SM의 구조는 아래와 같다.   

![img_2.png](/assets/blog/gpu/basic_structure/img_2.png)

SM당 포함하고 있는 것은 아래와 같다.
- 4개의 프로세싱 블록
- 128KB 크기의 L1 Data Cache이자 공유 메모리
- 4개의 Texture Unit
- 2개의 FP64 Unit

여기서 FP64 unit이라는건 부동 소수점 연산을 할 수 있는 유닛인데
64bit 크기의 부동소수점을 연산할 수 있는 회로라고 생각하면 된다.

### 3) Processing Block

각 프로세싱 블록은 아래와 같은 유닛들을 포함하고 있다.   
- FP32 or INT32 (32bit 부동소수점연산 혹은 32bit 정수연산)이 가능한 16개의 코어
- FP32 연산만 가능한 16개의 코어
- L0 명령어 캐시
- 1개의 Warp 스케줄러, 1개의 디스패치 유닛
- 1개의 64KB 레지스터 파일
- 1개의 SFU(Special Function Unit) : 삼각함수 같은 특수 함수 연산을 위한 유닛
- 4개의 로드/스토어 유닛
- 1개의 ADA 4세대 텐서코어

프로세싱 블럭마다 총 32개의 CUDA 코어가 있기에 한번에 처리하는 단위(Warp)가 32개의 스레드인것이며
최근에야 추가된 특수한 경우를 제외하고는 각 프로세싱 블럭에서 연산하는 것의 동기화를 할 수 없다.

> ※ 내용 업데이트 및 추가적인 검증 예정
{: .prompt-tip }

# 참고문헌
- 서강대학교 임인성 교수님 - 기초 GPU 프로그래밍 수업 자료
- [NVIDIA - NVIDIA ADA GPU ARCHITECTURE](https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf)
