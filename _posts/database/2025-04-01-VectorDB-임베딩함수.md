---
title: Vector DB - 임베딩 함수(Embedding Functions)
author: blakewoo
date: 2025-4-15 16:00:00 +0900
categories: [Database]
tags: [Database, DBMS ,VectorDB]
render_with_liquid: false
---

# Vector DB - Embedding Functions
## 1. 개요
벡터 데이터 베이스에 넣으려면 데이터를 벡터화 해야한다.  
데이터를 벡터화하기 위해서는 벡터화 함수가 필요하다.   

벡터화 함수는 여러 종류가 있으며, 심지어 같은 종류의 데이터라도 종류가 많다.

## 2. 텍스트 벡터화
텍스트도 단어와 문자 두 가지로 나뉜다.

### 1) 단어 임베딩
이전에 포스팅 해둔 것이 있으니 [이곳](https://blakewoo.github.io/posts/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9B%8C%EB%93%9C%EC%9E%84%EB%B2%A0%EB%94%A9/) 을 참조하는게 낫다.

### 2) 문장/문서 임베딩
단순한 단어와는 다르게 문장 자체를 임베딩하는 방식이다.

- Sentence Transformers   
  Transformer 기반 모델을 변형하여 문장 임베딩에 특화된 모델이다.   
  ex) all-MiniLM-L6-v2, text-embedding-ada-002, all-mpnet-base-v2, paraphrase-MiniLM-L6-v2, AlBERT, BERT, RoBERTa
  
- Universal Sentence Encoder   
  구글 리서치 팀에서 개발했으며 
  문장 단위의 의미를 효과적으로 캡처하도록 설계되어 검색,
  분류 등 여러 자연어 처리 응용에서 활용된다.   
  이 역시 Transformer를 사용하는 모델도 있지만 DAN 모델을 사용하는 것도 있어서 별도로 분리했다.
  
## 3. 이미지 벡터화
여기서도 어느 기반이냐에 따라 종류가 나뉜다.

### 1) CNN 기반
전통적인 합성곱 신경망 (Convolutional Neural Network)을 이용한 방식으로 시각적 특징을 추출하여
중간 레이어의 출력 값을 벡터로 활용한다.   
ex) ResNet, VGG, EfficientNet

### 2) Transformer 기반
- Vision Transformer (ViT)   
  Google Research, Brain Team에서 나온 논문에서 비롯된 방식이다.
  이미지 패치를 토큰으로 변환한 후 Transformer를 적용하여 이미지의 전역 정보를 학습한다.


- CLIP (Contrastive Language–Image Pre-training)   
  이미지와 텍스트를 동일한 벡터 공간에 임베딩하는 모델이다.

## 4. 음성 벡터화
- Wav2Vec2   
  자가 지도 학습(self-supervised learning)을 통해 음성의 특징을 추출한다.
  보통 음성 인식 분야에서 많이 활용되며, 임베딩 벡터로 변환해 다양한 다운스트림 작업에 적용할 수 있다.


- OpenL3   
  오디오의 시간적, 주파수적 특징을 동시에 고려하여 임베딩을 생성한다.


- Whisper (OpenAI)   
  주로 STT(음성-텍스트 변환)에 쓰이지만, 내부적으로 학습된 표현(representation)을 임베딩으로 활용하는 경우도 있다.

## 5. Vector file format
### 1) fvecs
32‑bit float 형식의 벡터들을 순차적으로 기록하며 파일은 “벡터 개수” 정보 없이, 각 벡터 앞에 4바이트로 차원(dimension)을 쓰고
그 뒤에 해당 차원 수만큼의 float32 값을 잇따라 저장하는 구조이다. SIFT1M, GIST1M, Deep1M, SIFT1B 등 ANN‑Benchmarks용 대규모 벤치마크
데이터셋 배포에 사용한다

### 2) bvecs
8‑bit unsigned integer(바이트) 형식의 벡터들을 fvecs와 동일한 방식으로 저장하며
주로 바이너리(descriptor) 기반 피처(예: BRIEF, ORB 등)나 메모리 절약이 중요한 경우에 사용한다.

### 3) .npy / .npz
NumPy 배열 단일·다중 저장할때 사용하며 
실질 구조는 아래와 같다.
- .npy   
  배열의 shape·dtype·엔디언 정보 포함한 바이너리 포맷

- .npz   
  내부에 여러 .npy 파일을 무압축 ZIP 아카이브로 저장
  
완전한 배열 재구성 정보 보존, 메모리 매핑 지원이 장점이지만 NumPy에 종속되기 때문에 다른 곳에서 쓰기 어렵고
타 언어 호환성 제한되기 때문에 확장성이 떨어진다.

### 4) .tfrecord
TensorFlow 입력 파이프라인용 레코드 시퀀스 저장한다. 총 3가지 타입이 있는데 각 타입은 하위 타입으로 강제 변환이 가능하다.
### tf.train.BytesList
- string
- byte
### tf.train.FloatList
- float ( float32 )
- double ( float64 )
### tf.train.Int64List
- bool
- enum
- int32
- uint32
- int64
- uint64

기본적으로 Protocol Buffers(tf.train.Example) 직렬화 메시지의 연속 기록으로 이루어져있으며
tf.data와 결합 시 파이프라인 최적화·병렬 I/O 지원을 지원하는 장점이 있으나 앞서 npy와 같이 특정 플랫폼
즉, TensorFlow 생태계 종속된다는 문제점이 있다.

> ※ 추가 업데이트 및 검증 예정이고, 아직 완벽하지 않으니 참고만 바란다.
{: .prompt-tip }


# 참고자료
- [밀버스 - 임베딩 함수](https://milvus.io/docs/ko/embeddings.md)
- [크로마 - 임베딩 함수](https://docs.trychroma.com/docs/embeddings/embedding-functions)
- [파인콘 - 임베딩 함수 고르기](https://www.pinecone.io/learn/series/rag/embedding-models-rundown/)
- [쿼드란트 - 임베딩 함수들](https://qdrant.tech/documentation/embeddings/)
- [밀버스 - 올바른 벡터 임베딩을 얻는 방법](https://milvus.io/ko/blog/how-to-get-the-right-vector-embeddings.md)
- [파인콘 - Creating Vector Embeddings](https://www.pinecone.io/learn/vector-embeddings/)
- Alexey Dosovitskiy, , Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." (2021).
- [OpenAI - CLIP: Connecting text and images](https://openai.com/index/clip/)
- Alec Radford, , Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. "Learning Transferable Visual Models From Natural Language Supervision." (2021).
- Alexei Baevski, , Henry Zhou, Abdelrahman Mohamed, and Michael Auli. "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations." (2020).
- Lan, Jiangyu, Shuai, Gao, Weiting, Zhang, Xindi, Hou, Minghui, Xi, Yuming, Zhang, Bo, Lei, Hongke, Zhang, and Xuemin Sherman, Shen. "OpenL3: Embedding Diverse Network Services Into MANETs Using Multi-Dimensional Identifier".IEEE Internet of Things Journal (2025): 1-1.
- Alec Radford, , Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. "Robust Speech Recognition via Large-Scale Weak Supervision." (2022).
- [Numpy - numpy.lib.format](https://numpy.org/devdocs/reference/generated/numpy.lib.format.html?utm_source=chatgpt.com)
- []()


