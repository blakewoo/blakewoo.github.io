---
title: 기계학습 - Deep learning - 퍼셉트론
author: blakewoo
date: 2025-2-15 23:00:00 +0900
categories: [Algorithm and AI]
tags: [Deep learning, AI, Machine Learning] 
render_with_liquid: false
use_math: true
---

# Deep learning
## 1. 개요
딥 러닝(Deep Learning)은 머신 러닝(Machine Learning)의 특정한 한 분야이다.
인간의 뇌세포를 모사한 형태인 퍼셉트론의 층을 연속적으로 깊게 쌓아올려 데이터를 학습하는 방식을 말한다. 
이를 인공 신경망(Artificial Neural Network)이라고도 한다.

딥 러닝이 화두가 되기 시작한 것은 2010년대의 비교적 최근인데 이론이 처음나온 것은 1957년이다.
초기 인공 신경망인 퍼셉트론에서부터 설명을 시작하여 층을 깊게 쌓아 학습하는 딥 러닝까지 이야기해보겠다.

## 2. 퍼셉트론(Perceptron)
퍼셉트론(Perceptron)은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로
다수의 입력으로부터 하나의 결과를 내보내는 알고리즘이다.   
아래의 그림 중 왼쪽은 인간의 뇌세포이고, 오른쪽은 퍼셉트론의 구조이다.

![img.png](/assets/blog/algorithm/AI/deeplearning/퍼셉트론/img.png)

인간의 뇌세포를 보면 많은 가지돌기(=수상돌기)가 나있고 이 가지돌기는 다른 뇌세포의 축삭에서 나온 축삭 말단과 연결되어있다.   
즉, 다수의 입력값이 있는 것이며 이 입력을 축삭을 통해서 다른 뇌세포로 전달한다.   
퍼셉트론은 이 구조를 그대로 모사한 것이다.
오른쪽 그림을 보자. 다수의 입력값에 한 개의 출력이다.
X는 입력값 Y는 출력 값이며 W는 가중치를 말한다.
각각의 입력값에는 각각의 가중치가 존재하는데,
이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미하는 것이다.

각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고,
각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는
인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력한다.
(임계치에 대해서는 추가적으로 포스팅이 있을 예정이다)   
이러한 함수를 계단 함수(Step function)라고 하며 Deep learning의 기초가 된다.
계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현하며 식으로 나타내면 아래와 같다.

$$ i\int \sum_{i}^{n}w_{i}x_{i} \geq \theta \rightarrow y = 1 $$
$$ i\int \sum_{i}^{n}w_{i}x_{i} < \theta \rightarrow y = 0 $$

여기서 임계치를 좌변으로 넘기고 편향(b)로 표현하며 이 역시 퍼셉트론의 입력으로 사용된다.   
이 퍼셉트론을 층으로 만들어서 사용하는게 인공신경망의 시작이다.

### 1) 단층 퍼셉트론(Single-Layer Perceptron)
층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어진다.
이때 이 각 단계를 보통 층(layer)이라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 한다.

![img_1.png](/assets/blog/algorithm/AI/deeplearning/퍼셉트론/img_1.png)

단층 퍼셉트론은 직선 하나로 두 영역을 나눌수 있는 문제에 대해서만 구현이 가능하다.   
이는 로지스틱 회귀가 활성함수(이에 대해서 추가적인 설명이 있을 것이다)를 제외한다면 단층 퍼셉트론과 동일하기 때문이다.

### 2) 다층 퍼셉트론(MultiLayer Perceptron, MLP)
단층에서 층을 더 쌓으면 만들 수 있는 것으로 단층 퍼셉트론은 입력층과 출력층만 존재하지만,
다층 퍼셉트론은 입력층과 출력증 중간에 층을 더 추가되었으며 이 중간 층을 은닉층(hidden layer)이라고 한다.

![img_2.png](/assets/blog/algorithm/AI/deeplearning/퍼셉트론/img_2.png)

이러한 은닉층이 2개 이상이 되면 심층 신경망(Deep Neural Network, DNN)이라고 한다.   
꼭 위와 같은 형태의 다층 퍼셉트론 뿐만 아니라 다른 변형된 신경망의 경우에도 은닉층이 2개 이상이라면 모두 심층 신경망이라고 한다.


# 참고 자료
- 인공지능 개념 및 응용 3판 Artificial Intelligence Concepts and Applications (2013년) - 도용태, 김일곤, 김종완, 박창현, 강병호 저,
  사이텍미디어
- [위키독스 - 딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)  
- Machine Learning, Tom Mitchell, McGraw Hill, 1997.
- [geeksforgeeks - Type of machine learning](https://www.geeksforgeeks.org/types-of-machine-learning/)
