---
title: ê¸°ê³„í•™ìŠµ - K-means
author: blakewoo
date: 2025-11-2 23:00:00 +0900
categories: [Machine Learning]
tags: [AI, Machine Learning, K-means]
render_with_liquid: false
use_math: true
---

# K-means
## 1. ê°œìš”
ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë¶„í• ë²•ì˜ ì¼ì¢…ì´ë‹¤.    
ì´ˆê¸°ì— Kê°œì˜ ì¤‘ì‹¬ì ì„ ì„ ì •í•˜ì—¬ í•´ë‹¹ ì¤‘ì‹¬ì ì„ ê¸°ì¤€ìœ¼ë¡œ ê° ì ë“¤ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹í•˜ì—¬ Kê°œì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ì‹ì´ë‹¤.
ì´ ì•Œê³ ë¦¬ì¦˜ì€ ììœ¨ í•™ìŠµì˜ ì¼ì¢…ìœ¼ë¡œ, ë ˆì´ë¸”ì´ ë‹¬ë ¤ ìˆì§€ ì•Šì€ ì…ë ¥ ë°ì´í„°ì— ë ˆì´ë¸”ì„ ë‹¬ì•„ì£¼ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

## 2. ì ˆì°¨
ê°€ì¥ ìµœì´ˆì˜ K-means ë°©ì‹ì˜ ì ˆì°¨ë¥¼ ì•„ë˜ì™€ ê°™ë‹¤.

(1) ê° ì ì„ ê°€ì¥ ê°€ê¹Œìš´(ìœ í´ë¦¬ë“œ) ì¤‘ì‹¬(centroid)ì— í• ë‹¹í•œë‹¤.
(2) ê° í´ëŸ¬ìŠ¤í„°ì˜ ì ë“¤ë¡œ í‰ê· (centroid)ì„ ê°±ì‹ í•˜ì—¬ í• ë‹¹ì´ ë°”ë€Œì§€ ì•Šìœ¼ë©´ ì¢…ë£Œí•œë‹¤.

ì§€ê¸ˆ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ë„ í¬ê²Œ ë‹¤ë¥´ì§€ëŠ” ì•Šì§€ë§Œ ì—¬ê¸°ì„œ ëª‡ ê°€ì§€ ë³€ê²½ì´ ìƒê¸°ë©´ì„œ ì¢…ë¥˜ê°€ ìƒê²¼ë‹¤.

### â€» ì˜ˆì‹œ
#### 1) ì´ˆê¸° ì„¤ì •
kê°€ 2ì¼ë•Œë¥¼ ìƒì •í•˜ì—¬ ì˜ˆë¥¼ ë“¤ì–´ë³´ì´ê² ë‹¤.
ì•„ë˜ëŠ” ì„ì˜ë¡œ ì„ ì •í•œ 2ì°¨ì› ë°ì´í„° 6ê°œì´ë‹¤.
A = (1.0, 2.0)
B = (1.5, 1.8)
C = (5.0, 8.0)
D = (8.0, 8.0)
E = (1.0, 0.6)
F = (9.0,11.0)

ì—¬ê¸°ì„œ ì¤‘ì‹¬ê°’ì´ë  ê°’ 2(K)ê°œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ ì •í•˜ê² ë‹¤.
ìœ 
centroidâ‚ = A = (1.0, 2.0)
centroidâ‚‚ = D = (8.0, 8.0)

#### 2) ë°˜ë³µ 1
ê° ì ì—ì„œ ë‘ ì¤‘ì‹¬ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•œë‹¤. [ìœ í´ë¦¬ë“œ ê±°ë¦¬](https://blakewoo.github.io/posts/A-STAR/) ë¡œ ê³„ì‚°í•˜ê² ë‹¤.

* A (1.0,2.0):   
d(A, centroidâ‚) = 0.000 (ìê¸° ìì‹ )   
d(A, centroidâ‚‚) = 9.220   
â†’ A â†’ centroidâ‚


* B (1.5,1.8):   
d(B, centroidâ‚) = 0.539   
d(B, centroidâ‚‚) = 8.983   
â†’ B â†’ centroidâ‚


* C (5.0,8.0):   
d(C, centroidâ‚) = 7.211   
d(C, centroidâ‚‚) = 3.000   
â†’ C â†’ centroidâ‚‚


* D (8.0,8.0):   
d(D, centroidâ‚) = 9.220   
d(D, centroidâ‚‚) = 0.000   
â†’ D â†’ centroidâ‚‚


* E (1.0,0.6):   
d(E, centroidâ‚) = 1.400   
d(E, centroidâ‚‚) = 10.186  
â†’ E â†’ centroidâ‚


* F (9.0,11.0):   
d(F, centroidâ‚) = 12.042   
d(F, centroidâ‚‚) = 3.162   
â†’ F â†’ centroidâ‚‚


ì²« ë°˜ë³µ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.   
- Cluster 1 (centroidâ‚ì— í• ë‹¹): {A, B, E}    
- Cluster 2 (centroidâ‚‚ì— í• ë‹¹): {C, D, F}

ì´ì œ ìƒˆ ì¤‘ì‹¬ì ì„ ì°¾ëŠ”ë‹¤.   
* Cluster1ì˜ ìƒˆ centroidâ‚' = mean{A, B, E}   
x = (1.0 + 1.5 + 1.0) / 3 = 3.5 / 3 = 1.166666... (â‰ˆ 1.1667)   
y = (2.0 + 1.8 + 0.6) / 3 = 4.4 / 3 = 1.466666... (â‰ˆ 1.4667)   
â†’ centroidâ‚' = (1.1666667, 1.4666667)


* Cluster2ì˜ ìƒˆ centroidâ‚‚' = mean{C, D, F}   
x = (5.0 + 8.0 + 9.0) / 3 = 22 / 3 = 7.333333... (â‰ˆ 7.3333)   
y = (8.0 + 8.0 + 11.0) / 3 = 27 / 3 = 9.0   
â†’ centroidâ‚‚' = (7.3333333, 9.0)

#### 2) ë°˜ë³µ 2
ìƒˆë¡œ êµ¬í•œ ì¤‘ì‹¬ì ì— ëŒ€í•´ì„œ ê° ì ì— ëŒ€í•œ í• ë‹¹ ë³€ê²½ì´ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤.   
- A: d(A, centroidâ‚') = 0.5588, d(A, centroidâ‚‚') = 9.4399 â†’ A â†’ centroidâ‚'   
- B: d(B, centroidâ‚') = 0.4714, d(B, centroidâ‚‚') = 9.2665 â†’ B â†’ centroidâ‚'   
- C: d(C, centroidâ‚') = 7.5749, d(C, centroidâ‚‚') = 2.5386 â†’ C â†’ centroidâ‚‚'   
- D: d(D, centroidâ‚') = 9.4540, d(D, centroidâ‚‚') = 1.2019 â†’ D â†’ centroidâ‚‚'   
- E: d(E, centroidâ‚') = 0.8825, d(E, centroidâ‚‚') = 10.5200 â†’ E â†’ centroidâ‚'   
- F: d(F, centroidâ‚') = 12.3388, d(F, centroidâ‚‚') = 2.6034 â†’ F â†’ centroidâ‚‚'   

í• ë‹¹ ê°’ì´ ë³€ê²½ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì•Œê³ ë¦¬ì¦˜ì´ ì¢…ë£Œëœë‹¤.

## 3. ë³€ìˆ˜ ì„ ì • ë°©ë²•
### 1) ì´ˆê¸°í™” ê¸°ë²•
ëˆˆì¹˜ ì±˜ê² ì§€ë§Œ ì´ K-means ë°©ì‹ì€ ì´ˆê¸°ê°’ì— ë§¤ìš° ë¯¼ê°í•˜ë‹¤.  
ë”°ë¼ì„œ ì´ˆê¸°ê°’ì„ ì œëŒ€ë¡œ ì„ ì •í•˜ì§€ ëª»í•˜ë©´ ì„±ëŠ¥ì´ ë§¤ìš° ë–¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤.

ì´ ì´ˆê¸°ê°’ì„ ì¡ëŠ” ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆë‹¤.

#### a. ë¬´ì‘ìœ„ ì„ íƒ
ë°ì´í„°ì—ì„œ ë¬´ì‘ìœ„ë¡œ kê°œì˜ ê´€ì¸¡ê°’ì„ ê³¨ë¼ ì²˜ìŒ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¼ëŠ”ë° ì´í›„ ê° í´ëŸ¬ìŠ¤í„°ì— ë°°ë‹¹ëœ ì ë“¤ì˜ í‰ê·  ê°’ì„ ì´ˆê¸° $\mu _{i}$ë¡œ ì„¤ì •í•œë‹¤
ì¤‘ì‹¬ì ì´ ê²°êµ­ì—ëŠ” ì‹¤ì œ êµ°ì§‘ì˜ ì¤‘ì•™ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” íŠ¹ì„±ì„ ì§€ë‹Œë‹¤. 

#### b. Forgy
ë°ì´í„°ì—ì„œ ë¬´ì‘ìœ„ë¡œ kê°œì˜ ê´€ì¸¡ê°’ì„ ê³¨ë¼ ì²˜ìŒ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¼ëŠ”ë°, ì´í›„ ì¤‘ì•™ê°’ì„ ë‚´ì„œ ì¡°ì •í•˜ì§€ ì•Šê³  ê·¸ ê°’ ìì²´ë¥¼ ì¤‘ì‹¬ì ìœ¼ë¡œ ì‚¼ëŠ”ë‹¤.

#### c. MacQueen
ë°ì´í„° ì§‘í•©ìœ¼ë¡œë¶€í„° ì„ì˜ì˜ kê°œì˜ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì—¬ ê° í´ëŸ¬ìŠ¤í„°ì˜ ì´ˆê¸° $\mu _{i}$ë¡œ ì„¤ì •í•œë‹¤.
ì´í›„ ì„ íƒë˜ì§€ ì•Šì€ ê° ë°ì´í„°ë“¤ì— ëŒ€í•´, í•´ë‹¹ ì ìœ¼ë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ì•„ ë°ì´í„°ë¥¼ ë°°ë‹¹í•œë‹¤.
ëª¨ë“  ë°ì´í„°ë“¤ì´ í´ëŸ¬ìŠ¤í„°ì— ë°°ë‹¹ë˜ê³  ë‚˜ë©´ ê° í´ëŸ¬ìŠ¤í„°ì˜ ë¬´ê²Œì¤‘ì‹¬ì„ ë‹¤ì‹œ ê³„ì‚°í•˜ì—¬ ì´ˆê¸° $\mu _{i}$ë¡œ ë‹¤ì‹œ ì„¤ì •í•œë‹¤.

ë¬´ì‘ìœ„ ì„ íƒë²•ê³¼ëŠ” ë‹¤ë¥´ê²Œ í‰ê· ì´ ì•„ë‹ˆë¼ ë¬´ê²Œì¤‘ì‹¬ìœ¼ë¡œ ì„ ì •í•˜ê¸° ë•Œë¬¸ì— ìµœì¢… ìˆ˜ë ´ì— ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ëŠ” ê²ƒì€ ë¹„êµì  ë¹ ë¥´ë‚˜,
ìµœì¢… ìˆ˜ë ´ì— í•´ë‹¹í•˜ëŠ” í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ëŠ” ê²ƒì€ ë§¤ìš° ëŠë¦¬ë‹¤

#### d. Kaufman
ì „ì²´ ë°ì´í„° ì§‘í•© ì¤‘ ê°€ì¥ ì¤‘ì‹¬ì— ìœ„ì¹˜í•œ ë°ì´í„°ë¥¼ ì²«ë²ˆì§¸ $\mu _{i}$ë¡œ ì„¤ì •í•œë‹¤.
ì´í›„ ì„ íƒë˜ì§€ ì•Šì€ ê° ë°ì´í„°ë“¤ì— ëŒ€í•´, ê°€ì¥ ê°€ê¹Œìš´ ë¬´ê²Œì¤‘ì‹¬ ë³´ë‹¤ ì„ íƒë˜ì§€ ì•Šì€ ë°ì´í„° ì§‘í•©ì— ë” ê·¼ì ‘í•˜ê²Œ ìœ„ì¹˜í•œ ë°ì´í„°ë¥¼ ë˜ ë‹¤ë¥¸
$\mu _{i}$ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì„ ì´ kê°œì˜ $\mu _{i}$ê°€ ì„¤ì •ë  ë•Œê¹Œì§€ ë°˜ë³µí•œë‹¤.

#### e. k-means ++
1. ë°ì´í„°ì—ì„œ ì„ì˜ì˜ í•œ ì ì„ ì²« ë²ˆì§¸ ì¤‘ì‹¬ìœ¼ë¡œ ê· ë“± ë¬´ì‘ìœ„ ì„ íƒí•œë‹¤.
2. ê° ì  ğ‘¥ì— ëŒ€í•´ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ”ë° í˜„ì¬ê¹Œì§€ ì„ íƒëœ ì¤‘ì‹¬ë“¤ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ê³¼ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬(ë˜ëŠ” ê±°ë¦¬ì˜ ì œê³±)ë¡œ ê³„ì‚°í•œë‹¤.
3. ë‹¤ìŒ ì¤‘ì‹¬ì€ ê° ì  ğ‘¥ê°€ ì„ íƒë  í™•ë¥ ì„ âˆ $D(x)^{2}$ ë¡œ í•˜ì—¬ ìƒ˜í”Œë§í•œë‹¤
4. 2â€“3ì„ ë°˜ë³µí•´ ì´ kê°œì˜ ì¤‘ì‹¬ì„ ì„ íƒí•œë‹¤.
5. ê·¸ ë‹¤ìŒë¶€í„°ëŠ” í‘œì¤€ k-means(Lloyd)ë¥¼ ìˆ˜í–‰í•´ ì¤‘ì‹¬ì„ ê°±ì‹ Â·ìˆ˜ë ´ì‹œí‚¨ë‹¤.

ìš”ì»¨ëŒ€ ë©€ë¦¬ ë–¨ì–´ì§„ ì ë“¤ì´ ë†’ì€ í™•ë¥ ë¡œ ë¨¼ì € ì„ íƒë˜ë¯€ë¡œ ì¤‘ì‹¬ë“¤ì´ ê³ ë¥´ê²Œ í¼ì§€ê²Œ ëœë‹¤.

### 2) Kê°’ ì„ ì •
#### a. Rule of thumb
#### b. Elbow Method
#### c. Information Criterion Approach

> ì¶”ê°€ ì—…ë°ì´íŠ¸ ì˜ˆì •
{: .prompt-tip }
# ì°¸ê³  ìë£Œ
- [ìœ„í‚¤ ë°±ê³¼ - K í‰ê·  ì•Œê³ ë¦¬ì¦˜](https://ko.wikipedia.org/wiki/K-%ED%8F%89%EA%B7%A0_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
- Lloyd, S. P., Least Squares Quantization in PCM, IEEE Transactions on Information Theory, vol. 28, no. 2, pp. 129â€“37, from https://www.cs.nyu.edu/~roweis/csc2515-2006/readings/lloyd57.pdf, March 1, 1982. DOI: 10.1109/TIT.1982.1056489
- McQueen, James B. "Some methods of classification and analysis of multivariate observations." . In Proc. of 5th Berkeley Symposium on Math. Stat. and Prob. (pp. 281â€“297).1967.
- Arthur, D. & Vassilvitskii, S., â€œk-means++: The Advantages of Careful Seedingâ€ (2007).

